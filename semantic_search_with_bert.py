# -*- coding: utf-8 -*-
"""semantic-search-with-bert.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NA33U5Dd9Q13tCW1ROiXqBtMe16XlUmM
"""

!pip install pinecone

import os
from getpass import getpass

os.environ["PINECONE_API_KEY"] = os.getenv("PINECONE_API_KEY") or getpass(
    "Enter PineCone API Key: "
)

import pandas as pd
from pinecone import Pinecone, ServerlessSpec
import pinecone
from sentence_transformers import SentenceTransformer

files = pd.read_csv("sample_data/course_section_descriptions.csv", encoding="windows-1252")

files.head()

files['unique_id'] = files["course_id"].astype(str) + '-' + files["section_id"].astype(str)
files['metadata'] = files.apply(lambda x: {"course_name": x["course_name"], "section_name": x["section_name"]}, axis=1)

model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')
bert_model = SentenceTransformer('sentence-transformers/multi-qa-distilbert-cos-v1')

def create_embedding(row):
  combined_text = row["course_name"] + " " + row["course_technology"] + " " + row["section_name"] + " " + row["section_description"]
  return bert_model.encode(combined_text, show_progress_bar=False)

files['embeddings'] = files.apply(create_embedding, axis=1)

pc = Pinecone(api_key=os.environ["PINECONE_API_KEY"], environment="gcp-starter")
pc.list_indexes()

index_name = 'bert'
dimension = 768
metric = 'cosine'

if index_name in [index_name for index in pc.list_indexes()]:
  pc.delete_index(index_name)
  print(f"Index {index_name} deleted")
else:
  print(f"Index {index_name} does not exist")

pc.create_index(
    name=index_name,
    dimension=dimension,
    metric=metric,
    spec=ServerlessSpec(
        cloud='aws',
        region='us-east-1'
    )
)

index = pc.Index("bert")
pc.list_indexes()

vectors_to_upsert = [(row["unique_id"], row["embeddings"].tolist(), row["metadata"]) for index, row in files.iterrows()]

index.upsert(vectors=vectors_to_upsert)

query = "ai engineering"

query_embedding = bert_model.encode(query, show_progress_bar=False).tolist()

query_result = index.query(
    vector=[query_embedding],
    top_k=5,
    include_metadata=True
)

score_threshold = 0.3

for match_embedding in query_result.matches:
  if match_embedding.score > score_threshold:
    course_details = match_embedding.get('metadata', {})
    course_name = course_details.get('course_name', 'Unknown Course')
    section_name = course_details.get('section_name', 'Unknown Section')
    section_description = course_details.get('section_description', 'Unknown Description')
    print(f"Course Name: {course_name}")
    print(f"Section Name: {section_name}, Section Description: {section_description}" )



